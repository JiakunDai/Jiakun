{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b41c3ada",
   "metadata": {},
   "source": [
    "Date: \n",
    "Student Name:\n",
    "Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0fb38",
   "metadata": {},
   "source": [
    "# AI Workshop #6\n",
    "# KNN for Building Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5543f13",
   "metadata": {},
   "source": [
    "## 6.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42026db7",
   "metadata": {},
   "source": [
    "In this workshop, we will learn how to build a recommendation system that will recommend movies that people might like to watch. \n",
    "\n",
    "We will learn about the **K-nearest neighbors classifier (KNN)** and see how to implement it. We use these concepts to discuss collaborative filtering and then use it to build a recommender system.\n",
    "\n",
    "By the end of this workshop, you will have a better understanding of these topics:\n",
    "- Extracting the nearest neighbors\n",
    "- Building a K-Nearest Neighbors classifier\n",
    "- Computing similarity scores\n",
    "- Finding similar users using collaborative filtering\n",
    "- Mini-project: Building a movie recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f324847d",
   "metadata": {},
   "source": [
    "## 6.2 Extracting the nearest neighbors (KNN)\n",
    "\n",
    "Recommender systems employ the concept of nearest neighbors to find good recommendations. \n",
    "\n",
    "The name **nearest neighbors** refers to the process of finding the closest data points to the input point from the given dataset. \n",
    "\n",
    "This is frequently used to build classification systems that classify a data point based on the proximity of the input data point to various classes. \n",
    "\n",
    "Let's see how to find the nearest neighbors for a given data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c92a9a",
   "metadata": {},
   "source": [
    "1. First, create a new Python file and import the following packages:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1022f5df",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970feb3",
   "metadata": {},
   "source": [
    "2. Define sample 2D data points (as example):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "771fdc8c",
   "metadata": {},
   "source": [
    "# Input data\n",
    "X = np.array([[2.1, 1.3], [1.3, 3.2], [2.9, 2.5], [2.7, 5.4], [3.8, 0.9], \n",
    "        [7.3, 2.1], [4.2, 6.5], [3.8, 3.7], [2.5, 4.1], [3.4, 1.9],\n",
    "        [5.7, 3.5], [6.1, 4.3], [5.1, 2.2], [6.2, 1.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c25140",
   "metadata": {},
   "source": [
    "3. Define the number of nearest neighbors you want to extract (k=5 in our case):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f685c7e1",
   "metadata": {},
   "source": [
    "# Number of nearest neighbors\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f59caf",
   "metadata": {},
   "source": [
    "4. Define a test data point that will be used to extract the K-nearest neighbors:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d93adf6",
   "metadata": {},
   "source": [
    "# Test datapoint \n",
    "test_datapoint = [4.3, 2.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9bc4e",
   "metadata": {},
   "source": [
    "5. Plot the input data using circular black markers:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "564c813d",
   "metadata": {},
   "source": [
    "# Plot input data \n",
    "plt.figure()\n",
    "plt.title('Input data')\n",
    "plt.scatter(X[:,0], X[:,1], marker='o', s=75, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e8bb3",
   "metadata": {},
   "source": [
    "6. Create and train a K-nearest neighbors model using the input data. Use this model to extract the nearest neighbors to the test data point:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceb4f4a6",
   "metadata": {},
   "source": [
    "# Build K Nearest Neighbors model\n",
    "knn_model = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(X)\n",
    "distances, indices = knn_model.kneighbors([test_datapoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e276a09",
   "metadata": {},
   "source": [
    "7. Print the nearest neighbors extracted from the model:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f215443",
   "metadata": {},
   "source": [
    "# Print the 'k' nearest neighbors\n",
    "print(\"\\nK Nearest Neighbors:\")\n",
    "for rank, index in enumerate(indices[0][:k], start=1):\n",
    "    print(str(rank) + \" ==>\", X[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40533733",
   "metadata": {},
   "source": [
    "8. Visualize the nearest neighbors:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59a26c77",
   "metadata": {},
   "source": [
    "# Visualize the nearest neighbors along with the test datapoint \n",
    "plt.figure()\n",
    "plt.title('Nearest neighbors')\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', s=75, color='k')\n",
    "plt.scatter(X[indices][0][:][:, 0], X[indices][0][:][:, 1], \n",
    "        marker='o', s=250, color='k', facecolors='none')\n",
    "plt.scatter(test_datapoint[0], test_datapoint[1],\n",
    "        marker='x', s=75, color='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fffe9f",
   "metadata": {},
   "source": [
    "9. If everything goes well. You should see the following 3 figures. \n",
    "\n",
    "<img src=\"./Fig/Fig6.1.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>\n",
    "\n",
    "<img src=\"./Fig/Fig6.2.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>\n",
    "\n",
    "<img src=\"./Fig/Fig6.3.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c205ed",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/note.png\" width = \"\" height = \"\" alt=\"Note\" align=left />\n",
    "\n",
    "1. The first screenshot represents the input data.\n",
    "2. The second screenshot represents the five nearest neighbors. The test data point is shown using a cross and the nearest neighbor points have been circled.\n",
    "3. The third figure shows the five points that are closest to the test data point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78249b",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/workshop.png\" width = \"\" height = \"\" alt=\"Supervised ML\" align=center />\n",
    "\n",
    "### Workshop 6.1 : K Nearest Neighbors (KNN) with your own implementation\n",
    "\n",
    "1. Combine all the above code and named it as **knn_system.py**.\n",
    "2. If everything is okay, you should see the above figures:input data points, marked KNN = 5 data points with the test point and the 5 K-NN points details. \n",
    "3. Save and submit the source code and these figures. \n",
    "4. Actually the KNN is just the combination of distance calculation + data point sorting with distance. To implement of your own KNN, try to write the KNN algorithm. \n",
    "5. Implement the knn(k, in_data, out_data) function with Python, where k is the KNN number, in_data and out_data are the lists of input data points and output data points respectively. \n",
    "6. Run and submit your **knn_own.py** program and compare it with the Python NearestNeighbors package in terms of running time. Which one is faster? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56636ca9",
   "metadata": {},
   "source": [
    "The KNN implementation is faster than the KNeighborsClassifier class from the sklearn library. This is because our implementation uses NumPy arrays for distance calculation and sorting instead of Python's native data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6261d6e",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/note.png\" width = \"\" height = \"\" alt=\"Note\" align=left />\n",
    "\n",
    "Now that we have learned how to construct and run a K-nearest neighbors model. In the next section, we will build on that knowledge and use it to build a **K-nearest neighbors classifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b307681",
   "metadata": {},
   "source": [
    "## 6.3 Building a K-nearest neighbors classifier\n",
    "\n",
    "A K-nearest neighbors classifier is a classification model that uses the **K-nearest neighbors** algorithm to classify a given data point. \n",
    "\n",
    "The algorithm finds the K closest data points in the training dataset to identify the category of the input data point. It will then assign a class to this data point based on a majority vote. \n",
    "\n",
    "From the list of those K data points, we look at the corresponding classes and pick the one with the highest number of votes. The value of K will depend on the problem at hand.\n",
    "\n",
    "Let's see how to build a classifier using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fb2ed",
   "metadata": {},
   "source": [
    "1. Create a new Python file and import the following packages:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c5b0f8f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e6720",
   "metadata": {},
   "source": [
    "2. Load the input data from data.txt. Each line contains comma-separated values and the data contains four classes:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08a600bf",
   "metadata": {},
   "source": [
    "# Load input data\n",
    "input_file = 'data.txt'\n",
    "data = np.loadtxt(input_file, delimiter=',')\n",
    "X, y = data[:, :-1], data[:, -1].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d81d81",
   "metadata": {},
   "source": [
    "3. Visualize the input data using four different marker shapes. We need to map the labels to corresponding markers, which is where the mapper variable comes into the picture:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e3dfb2b",
   "metadata": {},
   "source": [
    "# Plot input data\n",
    "plt.figure()\n",
    "plt.title('Input data')\n",
    "marker_shapes = 'v^os'\n",
    "mapper = [marker_shapes[i] for i in y]\n",
    "for i in range(X.shape[0]):\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker=mapper[i], \n",
    "            s=75, edgecolors='black', facecolors='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561ad2d",
   "metadata": {},
   "source": [
    "You should see this figure:\n",
    "\n",
    "<img src=\"./Fig/Fig6.4.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d49460",
   "metadata": {},
   "source": [
    "4. Define the number of nearest neighbors to be used:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aaba796",
   "metadata": {},
   "source": [
    "# Number of nearest neighbors \n",
    "num_neighbors = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44050002",
   "metadata": {},
   "source": [
    "5. Define the step size of the grid that will be used to visualize the boundaries of the classifier model:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e26a03f",
   "metadata": {},
   "source": [
    "# Step size of the visualization grid\n",
    "step_size = 0.01  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf96478",
   "metadata": {},
   "source": [
    "6. Create the K-nearest neighbors classifier model:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb22cbe2",
   "metadata": {},
   "source": [
    "# Create a K Nearest Neighbours classifier model \n",
    "classifier = neighbors.KNeighborsClassifier(num_neighbors, weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1277737",
   "metadata": {},
   "source": [
    "7. Train the model using the training data:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a95ad9e",
   "metadata": {},
   "source": [
    "# Train the K Nearest Neighbours model\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe006b",
   "metadata": {},
   "source": [
    "8. Create the mesh grid of values that will be used to visualize the grid:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "989c511b",
   "metadata": {},
   "source": [
    "# Create the mesh to plot the boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "x_values, y_values = np.meshgrid(np.arange(x_min, x_max, step_size), \n",
    "        np.arange(y_min, y_max, step_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4c314",
   "metadata": {},
   "source": [
    "9. Evaluate the classifier on all the points on the grid to create a visualization of the boundaries:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83b5c4f3",
   "metadata": {},
   "source": [
    "# Evaluate the classifier on all the points on the grid \n",
    "output = classifier.predict(np.c_[x_values.ravel(), y_values.ravel()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10e564",
   "metadata": {},
   "source": [
    "10. Create a color mesh to visualize the output:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fd14a55",
   "metadata": {},
   "source": [
    "# Visualize the predicted output \n",
    "output = output.reshape(x_values.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(x_values, y_values, output, cmap=cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8cd8b",
   "metadata": {},
   "source": [
    "11. Overlay the training data on top of this color mesh to visualize the data relative to the boundaries:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83dbe4da",
   "metadata": {},
   "source": [
    "# Overlay the training points on the map\n",
    "for i in range(X.shape[0]):\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker=mapper[i], \n",
    "            s=50, edgecolors='black', facecolors='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36022a",
   "metadata": {},
   "source": [
    "12. Set the X and Y limits along with the title:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7abf672c",
   "metadata": {},
   "source": [
    "plt.xlim(x_values.min(), x_values.max())\n",
    "plt.ylim(y_values.min(), y_values.max())\n",
    "plt.title('K Nearest Neighbors classifier model boundaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353801fb",
   "metadata": {},
   "source": [
    "You should see this figure that represents the classifier boundaries:\n",
    "\n",
    "<img src=\"./Fig/Fig6.5.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23872de4",
   "metadata": {},
   "source": [
    "13. Define a test data point to see how the classifier performs. Create a figure with training data points and a test data point to see where it lies:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff359085",
   "metadata": {},
   "source": [
    "# Test input datapoint\n",
    "test_datapoint = [5.1, 3.6]\n",
    "plt.figure()\n",
    "plt.title('Test datapoint')\n",
    "for i in range(X.shape[0]):\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker=mapper[i], \n",
    "            s=75, edgecolors='black', facecolors='none')\n",
    "\n",
    "plt.scatter(test_datapoint[0], test_datapoint[1], marker='x', \n",
    "        linewidth=6, s=200, facecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028b687",
   "metadata": {},
   "source": [
    "You should see this figure where X is the test point:\n",
    "\n",
    "<img src=\"./Fig/Fig6.6.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbc9ce",
   "metadata": {},
   "source": [
    "14. Extract the K-nearest neighbors to the test data point, based on the classifier model:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01e27b54",
   "metadata": {},
   "source": [
    "# Extract the K nearest neighbors\n",
    "_, indices = classifier.kneighbors([test_datapoint])\n",
    "indices = indices.astype(np.int)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac560a",
   "metadata": {},
   "source": [
    "15. Plot the K-nearest neighbors obtained in the previous step:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90281c79",
   "metadata": {},
   "source": [
    "# Plot k nearest neighbors\n",
    "plt.figure()\n",
    "plt.title('K Nearest Neighbors')\n",
    "\n",
    "for i in indices:\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker=mapper[y[i]], \n",
    "            linewidth=3, s=100, facecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c358970",
   "metadata": {},
   "source": [
    "16. Overlay the test data point:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87730989",
   "metadata": {},
   "source": [
    "plt.scatter(test_datapoint[0], test_datapoint[1], marker='x', \n",
    "        linewidth=6, s=200, facecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e746622",
   "metadata": {},
   "source": [
    "17. Overlay the input data:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88f27aeb",
   "metadata": {},
   "source": [
    "for i in range(X.shape[0]):\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker=mapper[i], \n",
    "            s=75, edgecolors='black', facecolors='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd0cd5",
   "metadata": {},
   "source": [
    "You should see this figure which shows the 12 nearest neighbors to the test data point:\n",
    "\n",
    "<img src=\"./Fig/Fig6.7.png\" width = \"\" height = \"\" alt=\"Figure\" align=center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbd990",
   "metadata": {},
   "source": [
    "18. Print the predicted output:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "327d72ca",
   "metadata": {},
   "source": [
    "print(\"Predicted output:\", classifier.predict([test_datapoint])[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234484c",
   "metadata": {},
   "source": [
    "You will see the following output, indicating that the model is predicting that the test\n",
    "data point belongs to class 1:\n",
    "\n",
    "**Predicted output: 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83323c2e",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/workshop.png\" width = \"\" height = \"\" alt=\"Supervised ML\" align=center />\n",
    "\n",
    "### Workshop 6.2 : KNN Classifier with your own implementation\n",
    "\n",
    "1. Combine all the above code and named it as **knn_classifier_system.py**.\n",
    "2. If everything is okay, you should see the above 4 figures and the predicted results. \n",
    "3. Save and submit the source code and these figures. \n",
    "4. Actually the KNN Classifier is a simple extension of the KNN algorithm with the inclusion of the class category. Try your own by writing the KNN Classifier algorithm.  \n",
    "5. Implement the knn_classifier function with Python, \n",
    "6. Run and submit your **knn_classifier_own.py** program and compare it with the Python package in terms of running time. Which one is faster? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b8b384",
   "metadata": {},
   "source": [
    "Our KNN classifier implementation is slightly slower than the KNeighborsClassifier class from the sklearn library. This is because our implementation runs in pure Python, and the KNeighborsClassifier class from sklearn uses more efficient data structures and algorithms, such as optimization algorithms such as Kd-trees, to speed up the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16685f",
   "metadata": {},
   "source": [
    "## 6.4 Computing similarity scores\n",
    "\n",
    "To build a recommendation system, it is important to understand how to compare various objects in the dataset. \n",
    "\n",
    "If the dataset consists of people and their various movie preferences, then in order to make a recommendation we need to understand how to compare any two people with one another. \n",
    "\n",
    "This is where the similarity score is important. The similarity score gives an idea of how similar two data points are.\n",
    "\n",
    "There are two scores that are used frequently in this domain – the **Euclidean score** and the **Pearson score**. The Euclidean score uses the Euclidean distance between two data points to compute the score. \n",
    "\n",
    "The value of the **Euclidean distance** can be unbounded. Hence, we take this value and convert it in a way that the Euclidean score ranges from 0 to 1. If the Euclidean distance between two objects is large, then the Euclidean score should be low because a low score indicates that the objects are not similar. Hence Euclidean distance is inversely proportional to Euclidean score.\n",
    "\n",
    "The Euclidean distance of two point p,q is given by:\n",
    "\n",
    "<img src=\"./Fig/Fig6.8.png\" width = \"500\" height = \"\" alt=\"Figure\" align=center/>\n",
    "\n",
    "The **Pearson score** is a measure of correlation between two data points. It uses the covariance between the two data points along with their individual standard deviations to compute the score. The score can range from -1 to +1. A score of +1 indicates that the data points are similar, and a score of -1 indicates that they are dissimilar. A score of 0 indicates that there is no correlation between them. \n",
    "\n",
    "The Pearson correlation of two point X,Y is given by:\n",
    "\n",
    "<img src=\"./Fig/Fig6.9.png\" width = \"500\" height = \"\" alt=\"Figure\" align=center/>\n",
    "\n",
    "Let's see how to compute these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e697fb1",
   "metadata": {},
   "source": [
    "1. Create a new Python file and import the following packages:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b9a8f89",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86671657",
   "metadata": {},
   "source": [
    "2. Build an argument parser to process the input arguments. It will accept two users and the type of score that it needs to use to compute the similarity score:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c735ce7a",
   "metadata": {},
   "source": [
    "def build_arg_parser():\n",
    "    parser = argparse.ArgumentParser(description='Compute similarity score')\n",
    "    parser.add_argument('--user1', dest='user1', required=True,\n",
    "            help='First user')\n",
    "    parser.add_argument('--user2', dest='user2', required=True,\n",
    "            help='Second user')\n",
    "    parser.add_argument(\"--score-type\", dest=\"score_type\", required=True, \n",
    "            choices=['Euclidean', 'Pearson'], help='Similarity metric to be used')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8e373",
   "metadata": {},
   "source": [
    "3. Define a function to compute the Euclidean score between the input users. If the users are not in the dataset, the code will raise an error:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "457662ce",
   "metadata": {},
   "source": [
    "# Compute the Euclidean distance score between user1 and user2 \n",
    "def euclidean_score(dataset, user1, user2):\n",
    "    if user1 not in dataset:\n",
    "        raise TypeError('Cannot find ' + user1 + ' in the dataset')\n",
    "\n",
    "    if user2 not in dataset:\n",
    "        raise TypeError('Cannot find ' + user2 + ' in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa4b81",
   "metadata": {},
   "source": [
    "4. Define a variable to track the movies that have been rated by both users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa476aa9",
   "metadata": {},
   "source": [
    "    # Movies rated by both user1 and user2\n",
    "    common_movies = {} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378481b",
   "metadata": {},
   "source": [
    "5. Extract the movies rated by both users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea761fd9",
   "metadata": {},
   "source": [
    "    for item in dataset[user1]:\n",
    "        if item in dataset[user2]:\n",
    "            common_movies[item] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c56e70",
   "metadata": {},
   "source": [
    "6. If there are no common movies, then the similarity score cannot be computed:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54c570a0",
   "metadata": {},
   "source": [
    "    # If there are no common movies between the users, \n",
    "    # then the score is 0 \n",
    "    if len(common_movies) == 0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c63b3",
   "metadata": {},
   "source": [
    "7. Compute the squared differences between the ratings and use it to compute the **Euclidean score**:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cae4ab5e",
   "metadata": {},
   "source": [
    "    squared_diff = [] \n",
    "\n",
    "    for item in dataset[user1]:\n",
    "        if item in dataset[user2]:\n",
    "            squared_diff.append(np.square(dataset[user1][item] - dataset[user2][item]))\n",
    "        \n",
    "    return 1 / (1 + np.sqrt(np.sum(squared_diff))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19e83b",
   "metadata": {},
   "source": [
    "8. Define a function to compute the **Pearson score** between the users in the given dataset. If the users are not found in the dataset, it raises an error:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d469c29",
   "metadata": {},
   "source": [
    "# Compute the Pearson correlation score between user1 and user2 \n",
    "def pearson_score(dataset, user1, user2):\n",
    "    if user1 not in dataset:\n",
    "        raise TypeError('Cannot find ' + user1 + ' in the dataset')\n",
    "\n",
    "    if user2 not in dataset:\n",
    "        raise TypeError('Cannot find ' + user2 + ' in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e7efa",
   "metadata": {},
   "source": [
    "9. Define a variable to track the movies that have been rated by both users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04bdfe67",
   "metadata": {},
   "source": [
    "    # Movies rated by both user1 and user2\n",
    "    common_movies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b5adb",
   "metadata": {},
   "source": [
    "10. Extract the movies rated by both users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bda6a91c",
   "metadata": {},
   "source": [
    "    for item in dataset[user1]:\n",
    "        if item in dataset[user2]:\n",
    "            common_movies[item] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78753a57",
   "metadata": {},
   "source": [
    "11. If there are no common movies, then we cannot compute the similarity score:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68457aa3",
   "metadata": {},
   "source": [
    "    num_ratings = len(common_movies) \n",
    "\n",
    "    # If there are no common movies between user1 and user2, then the score is 0 \n",
    "    if num_ratings == 0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa6f6e",
   "metadata": {},
   "source": [
    "12. Calculate the sum of ratings of all the movies that have been rated by both users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d8cebc6",
   "metadata": {},
   "source": [
    "    # Calculate the sum of ratings of all the common movies \n",
    "    user1_sum = np.sum([dataset[user1][item] for item in common_movies])\n",
    "    user2_sum = np.sum([dataset[user2][item] for item in common_movies])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762f134",
   "metadata": {},
   "source": [
    "13. Calculate the sum of squares of the ratings all the movies that have been rated by both the users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b64418d1",
   "metadata": {},
   "source": [
    "    # Calculate the sum of squares of ratings of all the common movies \n",
    "    user1_squared_sum = np.sum([np.square(dataset[user1][item]) for item in common_movies])\n",
    "    user2_squared_sum = np.sum([np.square(dataset[user2][item]) for item in common_movies])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7b47b",
   "metadata": {},
   "source": [
    "14. Calculate the sum of products of the ratings of all the movies rated by both the input users:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c81f6b17",
   "metadata": {},
   "source": [
    "    # Calculate the sum of products of the ratings of the common movies\n",
    "    sum_of_products = np.sum([dataset[user1][item] * dataset[user2][item] for item in common_movies])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c91764",
   "metadata": {},
   "source": [
    "15. Calculate the various parameters required to compute the Pearson score using the preceding computations:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c673ca4",
   "metadata": {},
   "source": [
    "    # Calculate the Pearson correlation score\n",
    "    Sxy = sum_of_products - (user1_sum * user2_sum / num_ratings)\n",
    "    Sxx = user1_squared_sum - np.square(user1_sum) / num_ratings\n",
    "    Syy = user2_squared_sum - np.square(user2_sum) / num_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30903",
   "metadata": {},
   "source": [
    "16. If there is no deviation, then the score is 0:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f857c921",
   "metadata": {},
   "source": [
    "    if Sxx * Syy == 0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e279bd",
   "metadata": {},
   "source": [
    "17. Return the Pearson score:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04585ef8",
   "metadata": {},
   "source": [
    "    return Sxy / np.sqrt(Sxx * Syy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76786016",
   "metadata": {},
   "source": [
    "18. Define the main function and parse the input arguments:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ae4b0b1",
   "metadata": {},
   "source": [
    "if __name__=='__main__':\n",
    "    args = build_arg_parser().parse_args()\n",
    "    user1 = args.user1\n",
    "    user2 = args.user2\n",
    "    score_type = args.score_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7f88b",
   "metadata": {},
   "source": [
    "19. Load the ratings from the file ratings.json into a dictionary:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b21041b",
   "metadata": {},
   "source": [
    "    ratings_file = 'ratings.json'\n",
    "\n",
    "    with open(ratings_file, 'r') as f:\n",
    "        data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2fcb2",
   "metadata": {},
   "source": [
    "20. Compute the similarity score based on the input arguments:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5e68d93",
   "metadata": {},
   "source": [
    "    if score_type == 'Euclidean':\n",
    "        print(\"\\nEuclidean score:\")\n",
    "        print(euclidean_score(data, user1, user2))\n",
    "    else: \n",
    "        print(\"\\nPearson score:\")\n",
    "        print(pearson_score(data, user1, user2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ea4e5",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/workshop.png\" width = \"\" height = \"\" alt=\"Supervised ML\" align=center />\n",
    "\n",
    "### Workshop 6.3 : Compute Similarity with Euclidean and Pearson Scores\n",
    "\n",
    "1. Combine all the above code and name it as **compute_scores.py**\n",
    "2. Use \"David Smith\" and \"Bill Duffy\" as example.\n",
    "3. Compute the Euclidean score by using:\n",
    "\n",
    "  **python compute_scores.py --user1 \"David Smith\" --user2 \"Bill Duffy\" --score-type Euclidean**\n",
    "  \n",
    "4. What is the Euclidean score?\n",
    "5. Compute the Pearson Score by using:\n",
    "    \n",
    "   **python3 compute_scores.py --user1 \"David Smith\" --user2 \"Bill Duffy\" --score-type Pearson**\n",
    "   \n",
    "6. What is the Pearson score?\n",
    "7. Save and submit the program code and score answers. \n",
    "8. Find two other actors and compare their Euclidean and Pearson scores. \n",
    "9. In a two-dimensional space, the **Manhattan distance** between two points (x1, y1) and (x2, y2) would be calculated as: distance = |x2 - x1| + |y2 - y1|. Or in general:\n",
    "\n",
    "<img src=\"./Fig/Fig6.10.png\" width = \"500\" height = \"\" alt=\"Figure\" align=center/>\n",
    "\n",
    "10. For your program, add the **Manhattan distance** implementation as additional score calculation and named as **\"Manhattan\"**.\n",
    "11. Using \"David Smith\" and \"Bill Duffy\" as example, compare their Euclidean, Pearson and Manhattan scores. Which one you think is better representation of similarity? Why?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba03328a",
   "metadata": {},
   "source": [
    "The Euclidean score computes the Euclidean distance between users on the co-rated movies, with a smaller distance indicating a higher similarity. The Euclidean score ranges from 0 to 1, with higher values indicating higher similarity.\n",
    "The Pearson score takes into account not only the rating differences between users on the co-rated movies, but also the overall tendency of their ratings. The Pearson score ranges from -1 to 1, with -1 indicating negative correlation, 0 indicating no correlation, and 1 indicating positive correlation, with values closer to 1 or -1 indicating higher similarity.\n",
    "the Euclidean score and Pearson score take different factors into account when calculating user similarity; the Euclidean score only takes into account the rating differences between users, while the Pearson score also takes into account the overall trend of users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38814994",
   "metadata": {},
   "source": [
    "Euclidean distance is the average difference between the preferences of two users. The smaller the value, the more similar the preferences are between the two users. In this example, the Euclidean distance between the two users is 0.707, indicating that they have similar preferences.\n",
    "The Pearson correlation coefficient measures the strength of the linear correlation between two users. The value is between -1 and 1, where closer to 1 indicates a stronger linear correlation between the two users. In this example, the Pearson correlation between the two users is 0.9909, which means that their preferences are very similar.\n",
    "The Manhattan distance measures the sum of the absolute values of the differences between the preferences of two users. In this example, the Manhattan distance between the two users is 1.0, which means that their preferences differ very much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ef0bf",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/note.png\" width = \"\" height = \"\" alt=\"Note\" align=left />\n",
    "\n",
    "In this section, we learned how to compute **similarity scores** and learned why that an important component in the construction of a recommender system. In the next section, we will learn how to identify users with similar preferences by using **collaborative filtering**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfb729",
   "metadata": {},
   "source": [
    "## 6.5 Finding similar users using collaborative filtering\n",
    "\n",
    "**Collaborative filtering** refers to the process of identifying patterns among the objects\n",
    "in a dataset in order to decide about a new object. \n",
    "\n",
    "In the context of recommendation engines, collaborative filtering is used to provide recommendations by looking at similar users in the dataset.\n",
    "\n",
    "<img src=\"./Fig/note.png\" width = \"\" height = \"\" alt=\"Note\" align=left />\n",
    "\n",
    "By collecting the preferences of different users in the dataset, we collaborate that information to filter the users. Hence the name **collaborative filtering**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aeebb4",
   "metadata": {},
   "source": [
    "The assumption here is that if two people have similar ratings for a set of movies, then their choices for a set of new unknown movies would be similar too. \n",
    "\n",
    "By identifying patterns in those common movies, predictions can be made about new movies. \n",
    "\n",
    "In the previous section, we learned how to compare different users in the dataset. \n",
    "\n",
    "The scoring techniques discussed will now be used to find similar users in the dataset. \n",
    "\n",
    "**Collaborative filtering algorithms** can be parallelized and be implemented in big data systems such as **AWS EMR** and **Apache Spark**, enabling the processing of hundreds of terabytes worth of data. \n",
    "\n",
    "These methods can be used for various verticals like finance, online shopping, marketing, customer studies, among others. \n",
    "\n",
    "Let's get started and build our collaborative filtering system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e8d9a",
   "metadata": {},
   "source": [
    "1. Create a new Python file and import the following packages:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82bbd00d",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from compute_scores import pearson_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379869c8",
   "metadata": {},
   "source": [
    "2. Define a function to parse the input arguments. The input argument is the name of the user:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a493478f",
   "metadata": {},
   "source": [
    "def build_arg_parser():\n",
    "    parser = argparse.ArgumentParser(description='Find users who are similar to the input user')\n",
    "    parser.add_argument('--user', dest='user', required=True,\n",
    "            help='Input user')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a777fe5",
   "metadata": {},
   "source": [
    "3. Define a function to find the users in the dataset that are similar to the given user. If the user is not in the dataset, raise an error:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b23cc7e",
   "metadata": {},
   "source": [
    "# Finds users in the dataset that are similar to the input user \n",
    "def find_similar_users(dataset, user, num_users):\n",
    "    if user not in dataset:\n",
    "        raise TypeError('Cannot find ' + user + ' in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf8211",
   "metadata": {},
   "source": [
    "4. The function to compute the Pearson score has been imported. Let's use that function to compute the Pearson score between the input user and all the other users in the dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa04e4af",
   "metadata": {},
   "source": [
    "    # Compute Pearson score between input user \n",
    "    # and all the users in the dataset\n",
    "    scores = np.array([[x, pearson_score(dataset, user, \n",
    "            x)] for x in dataset if x != user])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff1ff0",
   "metadata": {},
   "source": [
    "5. Sort the scores in descending order:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "500f4c79",
   "metadata": {},
   "source": [
    "    # Sort the scores in decreasing order\n",
    "    scores_sorted = np.argsort(scores[:, 1])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1891af",
   "metadata": {},
   "source": [
    "6. Extract the top num_users number of users as specified by the input argument and return the array:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be001757",
   "metadata": {},
   "source": [
    "    # Extract the top 'num_users' scores\n",
    "    top_users = scores_sorted[:num_users] \n",
    "\n",
    "    return scores[top_users] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874782b4",
   "metadata": {},
   "source": [
    "7. Define the main function and parse the input arguments to extract the name of the user:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ddc58e6",
   "metadata": {},
   "source": [
    "if __name__=='__main__':\n",
    "    args = build_arg_parser().parse_args()\n",
    "    user = args.user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e04596",
   "metadata": {},
   "source": [
    "8. Load the data from the movie ratings file ratings.json. This file contains the names of the people and their ratings for various movies:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a44c6256",
   "metadata": {},
   "source": [
    "    ratings_file = 'ratings.json'\n",
    "\n",
    "    with open(ratings_file, 'r') as f:\n",
    "        data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb484c2",
   "metadata": {},
   "source": [
    "9. Find the top three users who are like the user specified by the input argument. You can change it to any number of users depending on your choice. Print the output along with the scores:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52a7f59f",
   "metadata": {},
   "source": [
    "    print('\\nUsers similar to ' + user + ':\\n')\n",
    "    similar_users = find_similar_users(data, user, 3) \n",
    "    print('User\\t\\t\\tSimilarity score')\n",
    "    print('-'*41)\n",
    "    for item in similar_users:\n",
    "        print(item[0], '\\t\\t', round(float(item[1]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672afe29",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/workshop.png\" width = \"\" height = \"\" alt=\"Supervised ML\" align=center />\n",
    "\n",
    "### Workshop 6.4 : Collaborative Filtering\n",
    "\n",
    "1. Combine all the above code and name it as **collaborative_filtering.py**\n",
    "2. Use \"Bill Duffy\" as example to find the the users who are like Bill Duffy by using the following command:\n",
    "\n",
    "  **python collaborative_filtering.py --user \"Bill Duffy\"**\n",
    "  \n",
    "3. Save and submit the program code and output results. \n",
    "4. Check the results by using \"Samuel Miller\" and \"David Smith\". What is your findings?\n",
    "5. What are the major pros and cons of Collaborative Filtering? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ef1df08",
   "metadata": {},
   "source": [
    "From the output results, we can see that \"Chris Duncan\" is the user most similar to \"Samuel Miller\" and \"David Smith\" with a similarity score of 1, while \"bill duffy\" and \"David Smith\" with a similarity score of 0.99. The similarity scores of Adam Cohen and David Smith and Samuel Miller reached 0.91 and 0.8 respectively, indicating that their movie preferences were similar to those of input users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f24b55bb",
   "metadata": {},
   "source": [
    "advantages of Collaborative Filtering:\n",
    "Doesn't require knowledge about the items being recommended\n",
    "Can handle new items that were not in the training dataset\n",
    "Can provide personalized recommendations to users based on their preferences\n",
    "\n",
    "drawbacks of Collaborative Filtering:\n",
    "Requires a large dataset to train on in order to be effective\n",
    "Can suffer from the \"cold-start problem\" where new users or items have no or little information, making it difficult to provide accurate recommendations\n",
    "Can be biased towards popular items or users, leading to less diversity in recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981470a1",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/note.png\" width = \"\" height = \"\" alt=\"Note\" align=left />\n",
    "\n",
    "In this section, we learned how we can find users in a dataset that are like each other as well as being able to assign a score to determine how similar a user is to another. In the next section, we will put it all together and build our recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2881a",
   "metadata": {},
   "source": [
    "<img src=\"./Fig/mini-project.png\" width = \"\" height = \"\" alt=\"Mini-project\" align=center />\n",
    "\n",
    "\n",
    "## 6.6 Mini-project: Building a movie recommendation system\n",
    "\n",
    "So far, we have laid the foundation to build our recommendation system by learning about:\n",
    "- Extracting the nearest neighbors\n",
    "- Building a K-nearest neighbors classifier\n",
    "- Computing similarity scores\n",
    "- Finding similar users using collaborative filtering\n",
    "\n",
    "Now that all the building blocks in place, it's time to build a movie recommendation system. We learned all the underlying concepts that are needed to build a recommendation system. \n",
    "\n",
    "In this mini-project, we will build a **movie recommendation system** based on the data provided in the file ratings.json. \n",
    "\n",
    "This file contains a set of people and their ratings for various movies. \n",
    "\n",
    "To find movie recommendations for a given user, we need to find similar users in the dataset and then come up with recommendations for this person. \n",
    "\n",
    "Here are the basic steps:\n",
    "1. Create a new Python file and import the following packages.\n",
    "2. Define a function to parse the input arguments. The input argument is the name of the user.\n",
    "3. Define a function **get_recommendations(datasete, input_user)** to get the movie recommendations for a given user. If the user doesn't exist in the dataset, the code will raise an error.\n",
    "4. Define the variables **overall_scores and similarity_scores** to track the scores.\n",
    "5. Compute a similarity score (e.g. Pearson score) between the input user and all the other users in the dataset.\n",
    "6. If the similarity score is less than 0, you can continue with the next user in the dataset.\n",
    "7. Extract a list of movies that have been rated by the current user but haven't been rated by the input user.\n",
    "8. For each item in the filtered list, keep a track of the weighted rating based on the similarity score. Also keep a track of the similarity scores.\n",
    "9. If there are no such movies, then we cannot recommend anything.\n",
    "10. Normalize the scores based on the weighted scores.\n",
    "11. Sort the scores and extract the movie recommendations.\n",
    "12. Define the main function and parse the input arguments to extract the name of the input user.\n",
    "13. Load the movie ratings data from the file ratings.json.\n",
    "14. Extract the movie recommendations and print the output.\n",
    "15. Run the program by using the following command with \"Chris Duncun\" as example:\n",
    "\n",
    "  **python movie_recommender.py --user \"Chris Duncan\"**\n",
    "  \n",
    "  If everything go fine, you should see the following results:\n",
    "  \n",
    " <img src=\"./Fig/Fig6.11.png\" width = \"500\" height = \"\" alt=\"Figure\" align=center/>\n",
    " \n",
    "\n",
    "16. Save and submit your mini-project program code with results on: Chris Duncan, David Smith and Bill Duffy.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5bfa94",
   "metadata": {},
   "source": [
    "## 6.7 Summary\n",
    "\n",
    "In this workshop, we learned how to extract **K-nearest neighbors (KNN)** for a given data point from a given dataset. \n",
    "\n",
    "We then used this concept to build the **K-nearest neighbors (KNN)** classifier. \n",
    "\n",
    "We discussed how to compute similarity scores such as the **Euclidean** and **Pearson scores**. \n",
    "\n",
    "We learned how to use **collaborative filtering** to find similar users from a given dataset and used it to build a movie recommendation system. \n",
    "\n",
    "Finally, we were able to test our model and run it against data points that the system had not previously seen.\n",
    "\n",
    "In the next workshop, we will learn about **logic programming** and see how to build an inference engine that can solve real-world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4dca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
